{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "선형분류_16010170_윤재휘",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxNsMsY/ueFh6kLyF9yY7y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HwiHwi523/Course_AI_CoLab/blob/master/%EC%84%A0%ED%98%95%EB%B6%84%EB%A5%98_16010170_%EC%9C%A4%EC%9E%AC%ED%9C%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE6h7yBFy1nI",
        "colab_type": "code",
        "outputId": "7f8ea0f3-a3ab-4b06-d36a-ee561097426b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "! curl 'https://raw.githubusercontent.com/sejongresearch/2020.Spring.AI/master/HW/zoo_class.csv' -o 'zoo_class.csv'\n",
        "\n",
        "xy = np.loadtxt('zoo_class.csv', delimiter=',', dtype=np.float32)\n",
        "\n",
        "x_data = xy[:, 0:-1]\n",
        "y_data = xy[:, [-1]].squeeze()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r 53  3535   53  1875    0     0  10533      0 --:--:-- --:--:-- --:--:-- 10474\r100  3535  100  3535    0     0  19859      0 --:--:-- --:--:-- --:--:-- 19748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Menf-1uvy81K",
        "colab_type": "code",
        "outputId": "794642ea-be82-4422-d635-03494ef9d847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.LongTensor(y_data)\n",
        "\n",
        "# 7가지 클래스, 16가지 특징\n",
        "nb_class = 7\n",
        "nb_feature = 16\n",
        "nb_data = len(y_train)\n",
        "\n",
        "# One Hot Encoding에 쓰일 W, b 초기화\n",
        "W_one_hot = torch.zeros((nb_feature, nb_class), requires_grad=True)\n",
        "b_one_hot = torch.zeros(1, requires_grad=True)\n",
        "optimizer_one_hot = optim.SGD([W_one_hot, b_one_hot], lr = 10)\n",
        "\n",
        "# Cross Entropy에 쓰일 W, b 초기화\n",
        "W_cross_entropy = torch.zeros((nb_feature, nb_class), requires_grad = True)\n",
        "b_cross_entropy = torch.zeros(1, requires_grad = True)\n",
        "optimizer_cross_entropy = optim.SGD([W_cross_entropy, b_cross_entropy], lr = 10)\n",
        "\n",
        "nb_epochs = 100000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  # One-hot Encoding 방식\n",
        "  hypothesis = F.softmax(x_train.matmul(W_one_hot) + b_one_hot, dim = 1)\n",
        "\n",
        "  y_one_hot = torch.zeros(nb_data, nb_class)\n",
        "  y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\n",
        "  cost_one_hot = (y_one_hot * -torch.log(F.softmax(hypothesis, dim=1))).sum(dim=1).mean()\n",
        "\n",
        "  optimizer_one_hot.zero_grad()\n",
        "  cost_one_hot.backward()\n",
        "  optimizer_one_hot.step()\n",
        "\n",
        "  # Cross Entropy 방식\n",
        "  cost_cross_entropy = F.cross_entropy((x_train.matmul(W_cross_entropy) + b_cross_entropy), y_train)\n",
        "\n",
        "  optimizer_cross_entropy.zero_grad()\n",
        "  cost_cross_entropy.backward()\n",
        "  optimizer_cross_entropy.step()\n",
        "\n",
        "  if epoch % 10000 == 0:\n",
        "    print('Epoch {:6d}/{}'.format(epoch, nb_epochs))\n",
        "    print('- Cost (One Hot Encoding) = {}'.format(cost_one_hot))\n",
        "    print('- Cost (Cross Entropy) = {}'.format(cost_cross_entropy))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch      0/100000\n",
            "- Cost (One Hot Encoding) = 1.9459099769592285\n",
            "- Cost (Cross Entropy) = 1.9459086656570435\n",
            "Epoch  10000/100000\n",
            "- Cost (One Hot Encoding) = 1.1749634742736816\n",
            "- Cost (Cross Entropy) = 0.00011011224705725908\n",
            "Epoch  20000/100000\n",
            "- Cost (One Hot Encoding) = 1.1748980283737183\n",
            "- Cost (Cross Entropy) = 6.0981237766100094e-05\n",
            "Epoch  30000/100000\n",
            "- Cost (One Hot Encoding) = 1.17487633228302\n",
            "- Cost (Cross Entropy) = 4.2495623347349465e-05\n",
            "Epoch  40000/100000\n",
            "- Cost (One Hot Encoding) = 1.174865484237671\n",
            "- Cost (Cross Entropy) = 3.268423461122438e-05\n",
            "Epoch  50000/100000\n",
            "- Cost (One Hot Encoding) = 1.1748590469360352\n",
            "- Cost (Cross Entropy) = 2.6595262170303613e-05\n",
            "Epoch  60000/100000\n",
            "- Cost (One Hot Encoding) = 1.1748548746109009\n",
            "- Cost (Cross Entropy) = 2.2436663130065426e-05\n",
            "Epoch  70000/100000\n",
            "- Cost (One Hot Encoding) = 1.1748515367507935\n",
            "- Cost (Cross Entropy) = 1.940613947226666e-05\n",
            "Epoch  80000/100000\n",
            "- Cost (One Hot Encoding) = 1.1748493909835815\n",
            "- Cost (Cross Entropy) = 1.7109603504650295e-05\n",
            "Epoch  90000/100000\n",
            "- Cost (One Hot Encoding) = 1.1748477220535278\n",
            "- Cost (Cross Entropy) = 1.5292171156033874e-05\n",
            "Epoch 100000/100000\n",
            "- Cost (One Hot Encoding) = 1.1748461723327637\n",
            "- Cost (Cross Entropy) = 1.3840568499290384e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3FEXRSu_iUZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "05e1aa40-55a1-4acd-b7e3-1ebab3e319d1"
      },
      "source": [
        "# One Hot Encoding Prediction\n",
        "hypothesis = F.softmax(x_train.matmul(W_one_hot) + b_one_hot, dim = 1)\n",
        "predict_one_hot = torch.argmax(hypothesis, dim = 1)\n",
        "\n",
        "# Cross Entropy Prediction\n",
        "hypothesis = F.softmax(x_train.matmul(W_cross_entropy) + b_cross_entropy, dim = 1)\n",
        "predict_cross_entropy = torch.argmax(hypothesis, dim = 1)\n",
        "\n",
        "\n",
        "# Print Original Classification & Prediction\n",
        "print('# y_train #')\n",
        "print(y_train)\n",
        "print()\n",
        "\n",
        "print('## One Hot Encoding Prediction ##')\n",
        "print(predict_one_hot)\n",
        "print()\n",
        "\n",
        "print('## Cross Entropy Prediction ##')\n",
        "print(predict_cross_entropy)\n",
        "print()\n",
        "\n",
        "# Print Original Result & Prediction Results\n",
        "result_one_hot = predict_one_hot.float() == y_train\n",
        "result_cross_entropy = predict_cross_entropy.float() == y_train\n",
        "print()\n",
        "\n",
        "print('### One Hot Encoding Result ###')\n",
        "print(result_one_hot)\n",
        "print()\n",
        "\n",
        "print('### Cross Entropy Result ###')\n",
        "print(result_cross_entropy)\n",
        "print()\n",
        "\n",
        "# Print Accuracy\n",
        "accuracy_one_hot = list(result_one_hot).count(True) / len(result_one_hot)\n",
        "accuracy_cross_entropy = list(result_cross_entropy).count(True) / len(result_cross_entropy)\n",
        "print()\n",
        "\n",
        "print('#### One Hot Encoding Accuracy ####')\n",
        "print(accuracy_one_hot)\n",
        "print()\n",
        "\n",
        "print('#### Cross Entropy Accuracy ####')\n",
        "print(accuracy_cross_entropy)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# y_train #\n",
            "tensor([0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 1, 3, 6, 6, 6, 1, 0, 3, 0, 1, 1, 0, 1,\n",
            "        5, 4, 4, 0, 0, 0, 5, 0, 0, 1, 3, 0, 0, 1, 3, 5, 5, 1, 5, 1, 0, 0, 6, 0,\n",
            "        0, 0, 0, 5, 4, 6, 0, 0, 1, 1, 1, 1, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        6, 3, 0, 0, 2, 6, 1, 1, 2, 6, 3, 1, 0, 6, 3, 1, 5, 4, 2, 2, 3, 0, 0, 1,\n",
            "        0, 5, 0, 6, 1])\n",
            "\n",
            "## One Hot Encoding Prediction ##\n",
            "tensor([0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 1, 3, 6, 6, 6, 1, 0, 3, 0, 1, 1, 0, 1,\n",
            "        5, 4, 4, 0, 0, 0, 5, 0, 0, 1, 3, 0, 0, 1, 3, 5, 5, 1, 5, 1, 0, 0, 6, 0,\n",
            "        0, 0, 0, 5, 4, 6, 0, 0, 1, 1, 1, 1, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        5, 3, 0, 0, 2, 6, 1, 1, 2, 6, 3, 1, 0, 6, 3, 1, 5, 4, 2, 2, 3, 0, 0, 1,\n",
            "        0, 5, 0, 6, 1])\n",
            "\n",
            "## Cross Entropy Prediction ##\n",
            "tensor([0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 1, 3, 6, 6, 6, 1, 0, 3, 0, 1, 1, 0, 1,\n",
            "        5, 4, 4, 0, 0, 0, 5, 0, 0, 1, 3, 0, 0, 1, 3, 5, 5, 1, 5, 1, 0, 0, 6, 0,\n",
            "        0, 0, 0, 5, 4, 6, 0, 0, 1, 1, 1, 1, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        6, 3, 0, 0, 2, 6, 1, 1, 2, 6, 3, 1, 0, 6, 3, 1, 5, 4, 2, 2, 3, 0, 0, 1,\n",
            "        0, 5, 0, 6, 1])\n",
            "\n",
            "\n",
            "### One Hot Encoding Result ###\n",
            "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True])\n",
            "\n",
            "### Cross Entropy Result ###\n",
            "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
            "        True, True, True, True, True])\n",
            "\n",
            "\n",
            "#### One Hot Encoding Accuracy ####\n",
            "0.9900990099009901\n",
            "\n",
            "#### Cross Entropy Accuracy ####\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPGxHkjOII-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}